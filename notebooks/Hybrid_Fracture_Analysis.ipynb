{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dc526862",
      "metadata": {
        "id": "dc526862"
      },
      "source": [
        "# Pattern Recognition Part‑2\n",
        "This notebook **only runs scripts** from the GitHub repo:\n",
        "- Training: `python src/train.py`\n",
        "- Inference: `python src/main.py`\n",
        "- RQs: `python src/run_all_rqs.py ...` (RQ1–RQ5)\n",
        "- Optional Meta-learner stacking: `--with_meta` (runs inside RQ5)\n",
        "\n",
        "✅ Dataset is expected in the repo under `./data/`.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aaf826d2",
      "metadata": {
        "id": "aaf826d2"
      },
      "source": [
        "## Group & Roles\n",
        "- Project Title: `Hybrid Fracture Analysis`\n",
        "- Student 1 (Technical Lead ): `Kazeem Asiwaju-Bello`\n",
        "- Student 2 (Figures, Tables & Presentation): `OluwaTosin Ojo`\n",
        "- Student 3 (Report Lead): `Priyanka Mohan`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6626abb",
      "metadata": {
        "id": "e6626abb"
      },
      "outputs": [],
      "source": [
        "# Enable GPU (recommended): Runtime → Change runtime type → GPU\n",
        "\n",
        "import getpass, os, subprocess\n",
        "\n",
        "REPO = \"PatternRecognition_Hybrid-Fracture-Analysis-CNN\"\n",
        "URL  = \"https://github.com/MS-SE-Forge/PatternRecognition_Hybrid-Fracture-Analysis-CNN.git\"\n",
        "\n",
        "if not os.path.exists(REPO):\n",
        "    try:\n",
        "        subprocess.check_call([\"git\", \"clone\", URL])\n",
        "    except Exception:\n",
        "        token = getpass.getpass(\"GitHub Token (if private): \")\n",
        "        subprocess.check_call([\"git\", \"clone\", f\"https://{token}@github.com/MS-SE-Forge/PatternRecognition_Hybrid-Fracture-Analysis-CNN.git\"])\n",
        "else:\n",
        "    print(\"Repo already exists.\")\n",
        "\n",
        "%cd PatternRecognition_Hybrid-Fracture-Analysis-CNN\n",
        "\n",
        "!pip -q install torch torchvision opencv-python numpy scikit-image pillow scikit-learn matplotlib pandas openpyxl joblib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2faa36ba",
      "metadata": {
        "id": "2faa36ba"
      },
      "source": [
        "## Verify dataset exists in repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7b58143d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7b58143d",
        "outputId": "52e2402d-66c7-4ca2-daf8-ae37b40d7259"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test  train  val\n",
            "fractured  normal\n",
            "fractured  normal\n",
            "fractured  normal\n"
          ]
        }
      ],
      "source": [
        "!ls data\n",
        "!ls data/train\n",
        "!ls data/val\n",
        "!ls data/test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cfe9131",
      "metadata": {
        "id": "0cfe9131"
      },
      "source": [
        "## Train base model (script)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27a8ca84",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "27a8ca84",
        "outputId": "8e3e7171-a129-443b-e769-215c80d66f7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Initializing FractureCNN (resnet50) on: cuda\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100% 97.8M/97.8M [00:01<00:00, 74.8MB/s]\n",
            "Starting training: resnet50 | Aug: True | Pre: True\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Ep 1/15 - T.Loss: 0.426 T.Acc: 0.816 | V.Loss: 0.806 V.Acc: 0.744\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Ep 2/15 - T.Loss: 0.228 T.Acc: 0.915 | V.Loss: 0.519 V.Acc: 0.803\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Ep 3/15 - T.Loss: 0.165 T.Acc: 0.936 | V.Loss: 0.424 V.Acc: 0.869\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Ep 4/15 - T.Loss: 0.120 T.Acc: 0.961 | V.Loss: 0.213 V.Acc: 0.923\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Ep 5/15 - T.Loss: 0.108 T.Acc: 0.963 | V.Loss: 0.165 V.Acc: 0.935\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Ep 6/15 - T.Loss: 0.089 T.Acc: 0.971 | V.Loss: 0.371 V.Acc: 0.859\n"
          ]
        }
      ],
      "source": [
        "!python src/train.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec96220e",
      "metadata": {
        "id": "ec96220e"
      },
      "source": [
        "## Run inference / hybrid analysis (script)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c3a4603",
      "metadata": {
        "id": "2c3a4603"
      },
      "outputs": [],
      "source": [
        "!python src/main.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c166b3b",
      "metadata": {
        "id": "5c166b3b"
      },
      "source": [
        "## Run ALL 5 RQs and generate Figures_Tables.zip\n",
        "Set `WITH_META=True` to include meta-learner results inside RQ5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7271bcc",
      "metadata": {
        "id": "c7271bcc"
      },
      "outputs": [],
      "source": [
        "WITH_META = True\n",
        "EPOCHS = 15\n",
        "BATCH  = 32\n",
        "\n",
        "if WITH_META:\n",
        "    !python src/run_all_rqs.py --data ./data --epochs {EPOCHS} --batch_size {BATCH} --out ./Figures_Tables --with_meta\n",
        "else:\n",
        "    !python src/run_all_rqs.py --data ./data --epochs {EPOCHS} --batch_size {BATCH} --out ./Figures_Tables\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b74d6e2a",
      "metadata": {
        "id": "b74d6e2a"
      },
      "source": [
        "## Check outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9692eaa3",
      "metadata": {
        "id": "9692eaa3"
      },
      "outputs": [],
      "source": [
        "!find Figures_Tables -maxdepth 2 -type f | sort\n",
        "!ls -lh Figures_Tables.zip\n",
        "!unzip -l Figures_Tables.zip | head -n 160\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}